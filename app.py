import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import asyncio
import json
import time
from datetime import datetime

# Import our custom modules
from config.config_loader import ConfigLoader
from services.db_manager import DatabaseManager
from services.data_processor import DataProcessor

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Cloud PostgreSQL Performance Tester",
    page_icon="ğŸš€",
    layout="wide"
)

# Initialize session state
if 'test_results' not in st.session_state:
    st.session_state.test_results = None
if 'processing_stats' not in st.session_state:
    st.session_state.processing_stats = None
if 'data_processor' not in st.session_state:
    st.session_state.data_processor = None

# ë©”ì¸ íƒ€ì´í‹€
st.title("ğŸš€ Cloud PostgreSQL Performance Tester")
st.markdown("í´ë¼ìš°ë“œ 3ì‚¬(GCP, Azure, AWS) PostgreSQL ì„±ëŠ¥ ë¹„êµ ë„êµ¬")

st.markdown("---")

# ì‚¬ì´ë“œë°” ì„¤ì •
st.sidebar.header("âš™ï¸ í…ŒìŠ¤íŠ¸ ì„¤ì •")

# Load configuration
if 'config_loader' not in st.session_state:
    st.session_state.config_loader = ConfigLoader()

config_loader = st.session_state.config_loader

# í…ŒìŠ¤íŠ¸ ì„¤ì •
chunk_size = st.sidebar.slider("ì²­í¬ í¬ê¸°", 5, 50, 10, 5)
selected_clouds = st.sidebar.multiselect(
    "í…ŒìŠ¤íŠ¸í•  í´ë¼ìš°ë“œ",
    options=['gcp', 'azure', 'aws'],
    default=['gcp', 'azure', 'aws']
)

# Mock ëª¨ë“œ ì„¤ì •
mock_mode = st.sidebar.checkbox("Mock ëª¨ë“œ ì‚¬ìš©", value=True, help="ì‹¤ì œ DB ì—°ê²° ì—†ì´ ì‹œë®¬ë ˆì´ì…˜ìœ¼ë¡œ í…ŒìŠ¤íŠ¸")

st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ“Š ê²°ê³¼ ë‚´ë³´ë‚´ê¸°")

if st.session_state.test_results is not None:
    if st.sidebar.button("CSVë¡œ ë‚´ë³´ë‚´ê¸°"):
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        csv_path = f"results/test_results_{timestamp}.csv"
        st.session_state.data_processor.export_results_to_csv(csv_path)
        st.sidebar.success(f"ê²°ê³¼ê°€ {csv_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")

    if st.sidebar.button("JSONìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°"):
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        json_path = f"results/summary_{timestamp}.json"
        st.session_state.data_processor.export_summary_to_json(json_path)
        st.sidebar.success(f"ìš”ì•½ì´ {json_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")

# ë©”ì¸ ì½˜í…ì¸ 
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“¤ ë°ì´í„° ì—…ë¡œë“œ", "ğŸ“Š ì„±ëŠ¥ ë¹„êµ", "ğŸ“ˆ ìƒì„¸ ë¶„ì„", "âš™ï¸ ì„¤ì •"])

with tab1:
    st.header("ğŸ“¤ JSON ë°ì´í„° ì—…ë¡œë“œ")

    col1, col2 = st.columns([2, 1])

    with col1:
        # íŒŒì¼ ì—…ë¡œë“œ
        uploaded_file = st.file_uploader(
            "JSON íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
            type=['json'],
            help="í…ŒìŠ¤íŠ¸í•  JSON ë°ì´í„° íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”"
        )

        if uploaded_file is not None:
            try:
                data = json.load(uploaded_file)
                if isinstance(data, dict):
                    data = [data]

                st.success(f"âœ… {len(data)}ê°œì˜ ë ˆì½”ë“œê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")

                # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
                st.subheader("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
                df_preview = pd.DataFrame(data[:5])  # Show first 5 records
                st.dataframe(df_preview)

                # í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë²„íŠ¼
                if st.button("ğŸš€ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"):
                    if selected_clouds:
                        with st.spinner("í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘..."):
                            # Initialize database manager and data processor
                            db_manager = DatabaseManager(config_loader)
                            data_processor = DataProcessor(db_manager, chunk_size)

                            # Run the test
                            async def run_test():
                                return await data_processor.process_all_clouds(data, selected_clouds)

                            # Execute async function
                            loop = asyncio.new_event_loop()
                            asyncio.set_event_loop(loop)
                            processing_stats = loop.run_until_complete(run_test())
                            loop.close()

                            # Store results in session state
                            st.session_state.processing_stats = processing_stats
                            st.session_state.data_processor = data_processor
                            st.session_state.test_results = data_processor.get_performance_summary()

                        st.success("âœ… í…ŒìŠ¤íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! 'ì„±ëŠ¥ ë¹„êµ' íƒ­ì—ì„œ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                        # st.rerun()  # ì˜¤ë˜ëœ ë²„ì „ì—ì„œëŠ” ìë™ ë¦¬ë¡œë“œ ì•ˆí•¨
                    else:
                        st.error("í…ŒìŠ¤íŠ¸í•  í´ë¼ìš°ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”!")

            except json.JSONDecodeError:
                st.error("âŒ JSON íŒŒì¼ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤!")
            except Exception as e:
                st.error(f"âŒ íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

    with col2:
        st.subheader("ì˜ˆì‹œ ë°ì´í„°")
        if st.button("ğŸ“„ ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš©"):
            try:
                with open('data/sample_data.json', 'r', encoding='utf-8') as f:
                    sample_data = json.load(f)

                # ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                st.session_state.uploaded_data = sample_data
                st.success(f"âœ… {len(sample_data)}ê°œì˜ ìƒ˜í”Œ ë ˆì½”ë“œê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")

                # ìƒ˜í”Œ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
                st.subheader("ìƒ˜í”Œ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
                df_sample = pd.DataFrame(sample_data[:3])
                st.dataframe(df_sample)

            except Exception as e:
                st.error(f"ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")

        # ì„¸ì…˜ ìƒíƒœì— ë°ì´í„°ê°€ ìˆìœ¼ë©´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë²„íŠ¼ í‘œì‹œ
        if 'uploaded_data' in st.session_state and st.session_state.uploaded_data:
            data = st.session_state.uploaded_data
            st.write(f"í˜„ì¬ ë¡œë“œëœ ë°ì´í„°: {len(data)}ê°œ ë ˆì½”ë“œ")

            # í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë²„íŠ¼
            if st.button("ğŸš€ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰", key="sample_test_button"):
                if selected_clouds:
                    with st.spinner("í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘..."):
                        # Initialize database manager and data processor
                        db_manager = DatabaseManager(config_loader)
                        data_processor = DataProcessor(db_manager, chunk_size)

                        # Run the test
                        async def run_test():
                            return await data_processor.process_all_clouds(data, selected_clouds)

                        # Execute async function
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                        processing_stats = loop.run_until_complete(run_test())
                        loop.close()

                        # Store results in session state
                        st.session_state.processing_stats = processing_stats
                        st.session_state.data_processor = data_processor
                        st.session_state.test_results = data_processor.get_performance_summary()

                    st.success("âœ… í…ŒìŠ¤íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! 'ì„±ëŠ¥ ë¹„êµ' íƒ­ì—ì„œ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                    # st.experimental_rerun()  # ì˜¤ë˜ëœ ë²„ì „ì—ì„œëŠ” ìë™ ë¦¬ë¡œë“œ ì•ˆí•¨
                else:
                    st.error("í…ŒìŠ¤íŠ¸í•  í´ë¼ìš°ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”!")

with tab2:
    st.header("ğŸ“Š ì„±ëŠ¥ ë¹„êµ ê²°ê³¼")

    if st.session_state.test_results is not None:
        results = st.session_state.test_results
        stats = st.session_state.processing_stats

        # ì „ì²´ í†µê³„
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("ì´ ë ˆì½”ë“œ ìˆ˜", stats.total_records)
        with col2:
            st.metric("ì´ ì²­í¬ ìˆ˜", stats.total_chunks)
        with col3:
            st.metric("ì²˜ë¦¬ ì‹œê°„", f"{stats.processing_time:.2f}ì´ˆ")
        with col4:
            success_rate = (stats.success_count / (stats.success_count + stats.failure_count)) * 100
            st.metric("ì„±ê³µë¥ ", f"{success_rate:.1f}%")

        st.markdown("---")

        # í´ë¼ìš°ë“œë³„ ì„±ëŠ¥ ë¹„êµ
        col1, col2 = st.columns(2)

        with col1:
            st.subheader("í‰ê·  ì‹¤í–‰ ì‹œê°„ ë¹„êµ")

            cloud_names = []
            avg_times = []

            for cloud, data in results.items():
                if data['successful_operations'] > 0:
                    cloud_names.append(cloud.upper())
                    avg_times.append(data['average_execution_time'])

            if cloud_names:
                fig_bar = px.bar(
                    x=cloud_names,
                    y=avg_times,
                    labels={'x': 'Cloud Provider', 'y': 'Average Execution Time (seconds)'},
                    color=avg_times,
                    color_continuous_scale='Viridis'
                )
                fig_bar.update_layout(showlegend=False)
                st.plotly_chart(fig_bar, use_container_width=True)

        with col2:
            st.subheader("ì²˜ë¦¬ëŸ‰ ë¹„êµ (records/sec)")

            cloud_names = []
            throughput = []

            for cloud, data in results.items():
                if data['successful_operations'] > 0:
                    cloud_names.append(cloud.upper())
                    throughput.append(data['records_per_second'])

            if cloud_names:
                fig_throughput = px.bar(
                    x=cloud_names,
                    y=throughput,
                    labels={'x': 'Cloud Provider', 'y': 'Records per Second'},
                    color=throughput,
                    color_continuous_scale='Plasma'
                )
                fig_throughput.update_layout(showlegend=False)
                st.plotly_chart(fig_throughput, use_container_width=True)

        # ìƒì„¸ í†µê³„ í…Œì´ë¸”
        st.subheader("ìƒì„¸ ì„±ëŠ¥ í†µê³„")

        summary_data = []
        for cloud, data in results.items():
            summary_data.append({
                'Cloud': cloud.upper(),
                'ì´ ì‘ì—…': data['total_operations'],
                'ì„±ê³µ': data['successful_operations'],
                'ì‹¤íŒ¨': data['failed_operations'],
                'ì„±ê³µë¥  (%)': f"{data['success_rate']:.1f}",
                'í‰ê·  ì‹œê°„ (ì´ˆ)': f"{data['average_execution_time']:.4f}",
                'ìµœì†Œ ì‹œê°„ (ì´ˆ)': f"{data['min_execution_time']:.4f}",
                'ìµœëŒ€ ì‹œê°„ (ì´ˆ)': f"{data['max_execution_time']:.4f}",
                'ì²˜ë¦¬ëŸ‰ (records/sec)': f"{data['records_per_second']:.2f}"
            })

        df_summary = pd.DataFrame(summary_data)
        st.dataframe(df_summary, use_container_width=True)

    else:
        st.info("í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ë©´ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.")

with tab3:
    st.header("ğŸ“ˆ ìƒì„¸ ë¶„ì„")

    if st.session_state.data_processor is not None:
        processor = st.session_state.data_processor

        # ì‹œê°„ë³„ ì„±ëŠ¥ ë¶„ì„
        st.subheader("ì²­í¬ë³„ ì‹¤í–‰ ì‹œê°„ ë¶„ì„")

        results_by_cloud = processor.get_results_by_cloud()

        fig_timeline = go.Figure()

        for cloud, cloud_results in results_by_cloud.items():
            successful_results = [r for r in cloud_results if r.success]
            if successful_results:
                chunk_ids = [r.chunk_id for r in successful_results]
                exec_times = [r.execution_time for r in successful_results]

                fig_timeline.add_trace(go.Scatter(
                    x=chunk_ids,
                    y=exec_times,
                    mode='lines+markers',
                    name=cloud.upper(),
                    line=dict(width=2),
                    marker=dict(size=6)
                ))

        fig_timeline.update_layout(
            xaxis_title="Chunk ID",
            yaxis_title="Execution Time (seconds)",
            hovermode='x unified'
        )
        st.plotly_chart(fig_timeline, use_container_width=True)

        # ì‹¤í–‰ ì‹œê°„ ë¶„í¬
        st.subheader("ì‹¤í–‰ ì‹œê°„ ë¶„í¬")

        col1, col2 = st.columns(2)

        with col1:
            # Box plot
            fig_box = go.Figure()

            for cloud, cloud_results in results_by_cloud.items():
                successful_results = [r for r in cloud_results if r.success]
                if successful_results:
                    exec_times = [r.execution_time for r in successful_results]
                    fig_box.add_trace(go.Box(
                        y=exec_times,
                        name=cloud.upper(),
                        boxpoints='all',
                        jitter=0.3,
                        pointpos=-1.8
                    ))

            fig_box.update_layout(
                yaxis_title="Execution Time (seconds)",
                showlegend=False
            )
            st.plotly_chart(fig_box, use_container_width=True)

        with col2:
            # Histogram
            selected_cloud_detail = st.selectbox(
                "ë¶„ì„í•  í´ë¼ìš°ë“œ ì„ íƒ",
                options=list(results_by_cloud.keys()),
                format_func=lambda x: x.upper()
            )

            if selected_cloud_detail in results_by_cloud:
                cloud_results = results_by_cloud[selected_cloud_detail]
                successful_results = [r for r in cloud_results if r.success]

                if successful_results:
                    exec_times = [r.execution_time for r in successful_results]

                    fig_hist = px.histogram(
                        x=exec_times,
                        nbins=20,
                        labels={'x': 'Execution Time (seconds)', 'y': 'Count'},
                        title=f"{selected_cloud_detail.upper()} ì‹¤í–‰ ì‹œê°„ íˆìŠ¤í† ê·¸ë¨"
                    )
                    st.plotly_chart(fig_hist, use_container_width=True)

    else:
        st.info("í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ë©´ ìƒì„¸ ë¶„ì„ì´ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.")

with tab4:
    st.header("âš™ï¸ ì„¤ì •")

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì •")

        # í˜„ì¬ ì„¤ì • í‘œì‹œ
        db_config = config_loader.load_database_config()

        for cloud, config in db_config.get('clouds', {}).items():
            with st.expander(f"{cloud.upper()} ì„¤ì •"):
                st.code(f"""
Host: {config.get('host', 'Not set')}
Port: {config.get('port', 5432)}
Database: {config.get('database', 'Not set')}
User: {config.get('user', 'Not set')}
SSL Mode: {config.get('ssl_mode', 'require')}
                """)

    with col2:
        st.subheader("ìŠ¤í‚¤ë§ˆ ì„¤ì •")

        # í˜„ì¬ ìŠ¤í‚¤ë§ˆ í‘œì‹œ
        schema_config = config_loader.load_schema()

        st.code(f"Table Name: {schema_config.get('table_name', 'test_data')}")

        with st.expander("í•„ë“œ ì •ì˜"):
            for field_name, field_config in schema_config.get('fields', {}).items():
                st.write(f"**{field_name}**: {field_config.get('type', 'Unknown')} - {field_config.get('description', 'No description')}")

# í‘¸í„°
st.markdown("---")
st.markdown("ğŸš€ **Cloud PostgreSQL Performance Tester** - í´ë¼ìš°ë“œ ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ ë„êµ¬")