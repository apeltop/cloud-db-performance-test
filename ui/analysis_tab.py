"""
Detailed analysis tab component
"""
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import json
import os
from datetime import datetime
from pathlib import Path
from services.migration.test_run_manager import TestRunManager


def load_saved_migration_stats(test_output_dir: Path = None):
    """Load saved migration statistics from file"""
    if test_output_dir:
        stats_file = test_output_dir / "migration_stats.json"
    else:
        stats_file = Path("migration_outputs/migration_stats.json")

    if stats_file.exists():
        try:
            with open(stats_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get('batches', []), str(stats_file)
        except Exception as e:
            st.error(f"í†µê³„ íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return [], None
    return [], None


def load_test_results(test_output_dir: Path = None):
    """Load test results from file"""
    if test_output_dir:
        results_file = test_output_dir / "migration_results.json"
    else:
        results_file = Path("migration_outputs/migration_results.json")

    if results_file.exists():
        try:
            with open(results_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            st.error(f"ê²°ê³¼ íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None
    return None


def render_batch_statistics(batch_stats, data_source="real-time", file_path=None):
    """Render batch statistics section with filtering and charts"""
    if not batch_stats:
        return

    # Create DataFrame from batch stats
    df_batch_stats = pd.DataFrame(batch_stats)

    # Data source indicator
    if data_source == "saved" and file_path:
        mod_time = datetime.fromtimestamp(os.path.getmtime(file_path))
        st.info(f"ðŸ“ ì €ìž¥ëœ ë°ì´í„° (ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {mod_time.strftime('%Y-%m-%d %H:%M:%S')})")
    elif data_source == "real-time":
        st.success("ðŸ”´ ì‹¤ì‹œê°„ ë°ì´í„°")

    # Get unique table names for filtering
    unique_tables = df_batch_stats['table_name'].unique().tolist()

    # File/Table selection filter
    filter_option = st.selectbox(
        "ðŸ“ í…Œì´ë¸” ì„ íƒ",
        options=["ì „ì²´"] + unique_tables,
        key=f"table_filter_{data_source}"
    )

    # Filter data based on selection
    if filter_option == "ì „ì²´":
        filtered_stats = batch_stats
        filtered_df = df_batch_stats
    else:
        filtered_stats = [s for s in batch_stats if s['table_name'] == filter_option]
        filtered_df = df_batch_stats[df_batch_stats['table_name'] == filter_option].copy()
        # Reset batch numbers for filtered view
        filtered_df['batch_number'] = range(1, len(filtered_df) + 1)

    # Performance metrics
    if len(filtered_stats) > 0:
        latest_stats = filtered_stats[-1]
        recent_stats = filtered_stats[-min(5, len(filtered_stats)):]
        avg_recent_rps = sum(s['records_per_second'] for s in recent_stats) / len(recent_stats)
        avg_duration = sum(s['total_duration_seconds'] for s in filtered_stats) / len(filtered_stats)
        total_records = sum(s['records_count'] for s in filtered_stats)

        col1, col2, col3, col4, col5 = st.columns(5)
        with col1:
            st.metric("ì´ ë°°ì¹˜", len(filtered_stats))
        with col2:
            st.metric("ì´ ë ˆì½”ë“œ", f"{total_records:,}")
        with col3:
            st.metric("ìµœê·¼ ì²˜ë¦¬ëŸ‰", f"{latest_stats['records_per_second']:.1f} rec/s")
        with col4:
            st.metric("í‰ê·  ì²˜ë¦¬ëŸ‰", f"{avg_recent_rps:.1f} rec/s")
        with col5:
            st.metric("í‰ê·  ë°°ì¹˜ ì‹œê°„", f"{avg_duration:.3f}ì´ˆ")

    # Charts
    if not filtered_df.empty:
        if filter_option == "ì „ì²´":
            # Show separate charts for each table
            st.markdown("### ë°°ì¹˜ë³„ ì²˜ë¦¬ ì‹œê°„ ì¶”ì´")
            cols = st.columns(2)
            for idx, table in enumerate(unique_tables):
                table_df = filtered_df[filtered_df['table_name'] == table].copy()
                table_df['batch_number'] = range(1, len(table_df) + 1)

                with cols[idx % 2]:
                    fig = px.line(
                        table_df,
                        x='batch_number',
                        y='total_duration_seconds',
                        title=f'{table}',
                        labels={
                            'batch_number': 'ë°°ì¹˜ ë²ˆí˜¸',
                            'total_duration_seconds': 'ì²˜ë¦¬ ì‹œê°„ (ì´ˆ)'
                        },
                        markers=True
                    )
                    fig.update_layout(height=300, showlegend=False)
                    st.plotly_chart(fig, use_container_width=True)

            st.markdown("### ë°°ì¹˜ë³„ ì²˜ë¦¬ëŸ‰ ì¶”ì´")
            cols = st.columns(2)
            for idx, table in enumerate(unique_tables):
                table_df = filtered_df[filtered_df['table_name'] == table].copy()
                table_df['batch_number'] = range(1, len(table_df) + 1)

                with cols[idx % 2]:
                    fig = px.line(
                        table_df,
                        x='batch_number',
                        y='records_per_second',
                        title=f'{table}',
                        labels={
                            'batch_number': 'ë°°ì¹˜ ë²ˆí˜¸',
                            'records_per_second': 'ì²˜ë¦¬ëŸ‰ (records/sec)'
                        },
                        markers=True
                    )
                    fig.update_layout(height=300, showlegend=False)
                    st.plotly_chart(fig, use_container_width=True)

            # Cumulative records chart
            if 'cumulative_records' in filtered_df.columns:
                st.markdown("### ëˆ„ì  ë ˆì½”ë“œ ìˆ˜")
                cols = st.columns(2)
                for idx, table in enumerate(unique_tables):
                    table_df = filtered_df[filtered_df['table_name'] == table].copy()
                    table_df['batch_number'] = range(1, len(table_df) + 1)

                    with cols[idx % 2]:
                        fig = px.area(
                            table_df,
                            x='batch_number',
                            y='cumulative_records',
                            title=f'{table}',
                            labels={
                                'batch_number': 'ë°°ì¹˜ ë²ˆí˜¸',
                                'cumulative_records': 'ëˆ„ì  ë ˆì½”ë“œ ìˆ˜'
                            }
                        )
                        fig.update_layout(height=300, showlegend=False)
                        st.plotly_chart(fig, use_container_width=True)
        else:
            # Single table selected - show single charts
            fig_realtime = px.line(
                filtered_df,
                x='batch_number',
                y='total_duration_seconds',
                title=f'ë°°ì¹˜ë³„ ì²˜ë¦¬ ì‹œê°„ ì¶”ì´ - {filter_option}',
                labels={
                    'batch_number': 'ë°°ì¹˜ ë²ˆí˜¸',
                    'total_duration_seconds': 'ì²˜ë¦¬ ì‹œê°„ (ì´ˆ)'
                },
                markers=True
            )
            fig_realtime.update_layout(height=400)
            st.plotly_chart(fig_realtime, use_container_width=True)

            # Throughput trend
            fig_throughput_realtime = px.line(
                filtered_df,
                x='batch_number',
                y='records_per_second',
                title=f'ë°°ì¹˜ë³„ ì²˜ë¦¬ëŸ‰ ì¶”ì´ - {filter_option}',
                labels={
                    'batch_number': 'ë°°ì¹˜ ë²ˆí˜¸',
                    'records_per_second': 'ì²˜ë¦¬ëŸ‰ (records/sec)'
                },
                markers=True
            )
            fig_throughput_realtime.update_layout(height=400)
            st.plotly_chart(fig_throughput_realtime, use_container_width=True)

            # Cumulative records chart
            if 'cumulative_records' in filtered_df.columns:
                fig_cumulative = px.area(
                    filtered_df,
                    x='batch_number',
                    y='cumulative_records',
                    title=f'ëˆ„ì  ë ˆì½”ë“œ ìˆ˜ - {filter_option}',
                    labels={
                        'batch_number': 'ë°°ì¹˜ ë²ˆí˜¸',
                        'cumulative_records': 'ëˆ„ì  ë ˆì½”ë“œ ìˆ˜'
                    }
                )
                fig_cumulative.update_layout(height=400)
                st.plotly_chart(fig_cumulative, use_container_width=True)

        # Performance degradation warning (for filtered data)
        if len(filtered_stats) >= 3:
            recent_times = [s['total_duration_seconds'] for s in filtered_stats[-3:]]
            if all(recent_times[i] < recent_times[i+1] for i in range(len(recent_times)-1)):
                warning_msg = "âš ï¸ ì„±ëŠ¥ ì €í•˜ ê°ì§€: ìµœê·¼ 3ê°œ ë°°ì¹˜ì˜ ì²˜ë¦¬ ì‹œê°„ì´ ê³„ì† ì¦ê°€í•˜ê³  ìžˆìŠµë‹ˆë‹¤."
                if filter_option != "ì „ì²´":
                    warning_msg += f" (í…Œì´ë¸”: {filter_option})"
                st.warning(warning_msg)


def render_analysis_tab():
    """Render detailed analysis tab"""
    st.header("ðŸ“ˆ ìƒì„¸ ë¶„ì„")

    # Initialize test run manager
    test_manager = TestRunManager()

    # Get all completed test runs
    all_test_runs = test_manager.get_test_runs_by_status("completed")

    if not all_test_runs:
        st.info("ì™„ë£Œëœ í…ŒìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. CLIë¥¼ í†µí•´ ë§ˆì´ê·¸ë ˆì´ì…˜ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        st.code("python migrate_cli.py --batch-size 1000 --connections 1")
        return

    # Test selection dropdown
    st.subheader("ðŸŽ¯ ë¶„ì„í•  í…ŒìŠ¤íŠ¸ ì„ íƒ")

    test_options = {}
    for tr in all_test_runs:
        label = f"{tr['timestamp'][:19]} - {tr['cloud_provider']} {tr['instance_type']} (batch:{tr['batch_size']}, conn:{tr['num_connections']}) - {tr.get('average_records_per_second', 0):.0f} rec/s"
        test_options[label] = tr['test_id']

    selected_label = st.selectbox(
        "í…ŒìŠ¤íŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš”",
        options=list(test_options.keys()),
        index=0
    )

    selected_test_id = test_options[selected_label]
    selected_test = test_manager.get_test_run(selected_test_id)
    test_output_dir = test_manager.get_test_output_dir(selected_test_id)

    if not test_output_dir:
        st.error("í…ŒìŠ¤íŠ¸ ì¶œë ¥ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    st.markdown("---")

    # Load and display file results from migration
    st.subheader("ðŸ“ íŒŒì¼ë³„ ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ê³¼")

    results = load_test_results(test_output_dir)
    if results:
        if results.get('status') == 'completed':
            # Summary metrics
            col_a, col_b, col_c = st.columns(3)
            with col_a:
                st.metric("ì´ íŒŒì¼", results.get('total_files', 0))
            with col_b:
                st.metric("âœ… ì„±ê³µ", results.get('successful', 0))
            with col_c:
                st.metric("âŒ ì‹¤íŒ¨", results.get('failed', 0))

            # File results table
            file_results = results.get('file_results', [])
            if file_results:
                df_file_results = pd.DataFrame(file_results)
                # Select and rename columns
                display_cols = ['filename', 'table', 'status', 'records_inserted']
                df_display = df_file_results[display_cols].copy()
                df_display.columns = ['íŒŒì¼ëª…', 'í…Œì´ë¸”', 'ìƒíƒœ', 'ì‚½ìž…ëœ ë ˆì½”ë“œ']
                df_display['ìƒíƒœ'] = df_display['ìƒíƒœ'].map({
                    'success': 'âœ… ì„±ê³µ',
                    'error': 'âŒ ì‹¤íŒ¨',
                    'skipped': 'âš ï¸ ê±´ë„ˆëœ€'
                })
                st.dataframe(df_display, use_container_width=True)
            else:
                st.info("íŒŒì¼ë³„ ê²°ê³¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("ì™„ë£Œëœ ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("---")

    # Load and display batch statistics for selected test
    st.subheader("ðŸ“Š ë°°ì¹˜ ì„±ëŠ¥ í†µê³„")

    saved_stats, stats_file = load_saved_migration_stats(test_output_dir)

    if saved_stats:
        render_batch_statistics(saved_stats, data_source="saved", file_path=stats_file)
    else:
        st.info("ì„ íƒí•œ í…ŒìŠ¤íŠ¸ì˜ ë°°ì¹˜ í†µê³„ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")